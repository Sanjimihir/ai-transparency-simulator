# AI Transparency Simulator
### Loan Decision Explainability & Trust Simulation

## Overview

The **AI Transparency Simulator** is an interactive Streamlit-based application that demonstrates
**AI transparency, explainability, and user trust** in automated loan approval systems.

The project simulates how different explanation techniques—ranging from **no explanation**
to **SHAP-based explanations and counterfactual reasoning**—affect user trust in
AI-driven financial decisions.

This simulator is designed for **finance analytics, explainable AI (XAI) education,
AI ethics research, and transparency-focused system design**.

---

## Objectives

- Simulate automated loan approval decisions
- Provide multiple levels of model explainability
- Enable interactive user input and scenario testing
- Capture user trust under different explanation modes
- Demonstrate responsible AI practices in financial decision systems

---

## Explanation Modes

1. **No Explanation (Control)**
   - Displays only the prediction and probability

2. **Basic Explanation**
   - Shows top contributing features using model feature importance

3. **Detailed Explanation (SHAP)**
   - Displays SHAP values to explain individual predictions

4. **Counterfactual Explanations**
   - Suggests minimal feature changes required to alter the decision outcome

---

## System Workflow

